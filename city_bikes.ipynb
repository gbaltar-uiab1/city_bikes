{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6326067",
   "metadata": {},
   "source": [
    "# Data Analysis Project City Bike NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942e669",
   "metadata": {},
   "source": [
    "**Goals**<br>\n",
    "This dataset contains a sample of bike trips from the City Bike system in New York City.\n",
    "Each row represents one trip and includes information about the start and end stations, the duration, the\n",
    "user type, and other contextual data like age, season, temperature, and weekday.\n",
    "Your goal is to explore this dataset and extract insights through data analysis with Pandas.\n",
    "\n",
    "You'll practice basic pandas operations (loading, exploring, cleaning, transforming, summarizing) and use descriptive statistics and simple visualizations to support your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d87890",
   "metadata": {},
   "source": [
    "## 1. Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713eeac1",
   "metadata": {},
   "source": [
    "Environment requirements: Jupyter, Python, ipython, \n",
    "pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c815d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas openpyxl\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef672732",
   "metadata": {},
   "source": [
    "### What information does each column contain?\n",
    "\n",
    "Each row contains a record of a trip or unit of service usage: a bicycle was collected by a user somewhere sometime, used for a certain period of time and returned. It also contains information about the user's demographics and whether or not they are enrolled service members.\n",
    "\n",
    "Looking at the Dataframe we can see there are a few columns,\n",
    "['Start Time', 'Stop Time', 'Start Station ID', 'Start Station Name',<br>\n",
    "       'End Station ID', 'End Station Name', 'Bike ID', 'User Type',<br>\n",
    "       'Birth Year', 'Age', 'Age Groups', 'Trip Duration',<br>\n",
    "       'Trip_Duration_in_min', 'Month', 'Season', 'Temperature', 'Weekday'],<br>\n",
    "\n",
    "```'Start Time'```, ```'Stop Time'```: Show when the bicycle was picked up and when it was returned.<br>\n",
    "```'Start Station ID'```, ```'End Station ID'```: The IDs of stations where bicycles were collected and returned.<br>\n",
    "```'Start Station Name'```, ```'End Station Name'```: The station names corresponding to the Station IDs (vid. infra.)<br>\n",
    "```'Bike ID'```: the unique ID for the bike used for the trip.<br>\n",
    "```'User Type'```: whether the user is a member or not.<br>\n",
    "```'Birth Year'```, ```'Age'```, ```'Age Groups'```: user demographic information (vid. infra.)<br>\n",
    "```'Trip Duration'```, ```'Trip_Duration_in_min'```: Time elapsed between bicycle collection and return. Available in seconds and minutes (vid. infra.)<br>\n",
    "```'Month'```, ```'Season'```: Colums related to time of year. (NB. there appear to be records only for January through March.) <br>\n",
    "```'Temperature'```: the only weather mesurement available in the dataset. This will likely hinder any advanced weather-related insight, as we have no\n",
    "information about rain, snow, etc.<br>\n",
    "```'Weekday'```: using this column we might know what age groups use bicycles more often, as well as test assumptions on current bicycle usage.<br><br>\n",
    "\n",
    "There appears to be strong correlation among certain fields -- likely the result of calculated fields,\n",
    "\n",
    "- ```'Birth Year'```, ```'Age'``` and ```'Age Groups'```\n",
    "- ```'Trip Duration'``` and ```'Trip_Duration_in_min'``` (both are obtained from either ```'Start Time'``` or ```'Stop Time'``` as they are in full date format.)\n",
    "- ```'Month'``` and ```'Season'```, ```'Weekday'``` (same as above.)\n",
    "\n",
    "Also, there is some data duplication as there is no relational database, namely;\n",
    "\n",
    "- ```'Start Station Name'``` and ```'End Station Name'``` will correspond to the same IDs (ie. ```'Start Station ID'``` or ```'End Station ID'```, respectively.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pandas dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('ny_citibikes_raw.xlsx', sheet_name='NYCitiBikes')\n",
    "\n",
    "# Test df has loaded up\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List column names\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347f2aa",
   "metadata": {},
   "source": [
    "### Are there missing or duplicated values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a8c962",
   "metadata": {},
   "source": [
    "We can see a single missing value in column **'End Station Name'** and *3,555 duplicate rows* across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isna, drop, null values?\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicate_rows}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e787c",
   "metadata": {},
   "source": [
    "We can either recover the End Station Name from the End Station ID, or just drop the row. Since this just affects one row and we don't know if the error might have corrupted other values it's probably best to just drop (delete) the row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing row and drop it.\n",
    "print(\"Row count:\", len(df))\n",
    "print(\"Locating the row with missing values...\")\n",
    "missing_row = df[df['End Station Name'].isna()]\n",
    "print(\"Total number of missing rows located: \", missing_row.shape[0])\n",
    "\n",
    "print(\"Deleting rows with missing values...\")\n",
    "df = df.dropna(subset=['End Station Name'])\n",
    "print(\"Rows deleted\")\n",
    "print(\"New row count:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb138f55",
   "metadata": {},
   "source": [
    "Now let's delete the Duplicate Rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e556972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows and chech row totals.\n",
    "\n",
    "print(\"Row count:\", len(df))\n",
    "print(\"Total duplicate rows:\", duplicate_rows)\n",
    "print(\"Expected rows after duplicate deletion:\",(len(df) - duplicate_rows))\n",
    "print(\"Deleting duplicate rows...\")\n",
    "df = df.drop_duplicates()\n",
    "print(\"New row count:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8653dc41",
   "metadata": {},
   "source": [
    "### What is the overall time span of the trips? (overall time range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbc516",
   "metadata": {},
   "source": [
    "\n",
    "To calculate the overall time range, we find the oldest bicycle pickup timestamp, the most recent bicycle drop timestamp, and we subtract (newest - oldest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find latest and newest record and subtract\n",
    "\n",
    "oldest_timestamp = df['Start Time'].min()\n",
    "newest_timestamp = df['Stop Time'].max()\n",
    "print(\"Oldest trip start Timestamp:\\t\", oldest_timestamp)\n",
    "print(\"Newest trip stop Timestamp:\\t\", newest_timestamp)\n",
    "print(\"Overall time range:\\t\\t\", (newest_timestamp - oldest_timestamp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81022f3",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b0d48",
   "metadata": {},
   "source": [
    "### What is the average trip duration (in minutes)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trip_mins = df['Trip_Duration_in_min'].mean()\n",
    "print(f\"Average trip duration: {avg_trip_mins:.2f} mins.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfdb49",
   "metadata": {},
   "source": [
    "### What is the minimum and maximum duration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_trip_mins = df['Trip_Duration_in_min'].min()\n",
    "max_trip_mins = df['Trip_Duration_in_min'].max()\n",
    "print(\"Minimum trip duration:\",min_trip_mins)\n",
    "print(\"Maximum trip duration:\",max_trip_mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21e7d8",
   "metadata": {},
   "source": [
    "### What are the most common start and end stations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1db4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_start_station = df['Start Station Name'].value_counts().head(1)\n",
    "top_end_station = df['End Station Name'].value_counts().head(1)\n",
    "\n",
    "print(f\"Top start station:\\t{top_start_station.index[0]}. Trip count:\\t{top_start_station.iloc[0]}\")\n",
    "print(f\"Top end station:\\t{top_end_station.index[0]}. Trip count:\\t{top_end_station.iloc[0]}\")\n",
    "\n",
    "# station_name = top_station.index[0]\n",
    "# trip_count = top_station.iloc[0]\n",
    "\n",
    "# print(top_start_station)\n",
    "# print(top_end_station)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875e2ed",
   "metadata": {},
   "source": [
    "## 3. Users and Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22402f46",
   "metadata": {},
   "source": [
    "### How many unique bikes were used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0a68c",
   "metadata": {},
   "source": [
    "We use ```.nunique()``` which is the unique count method. It returns the count of all distinct values of a a column, in this case *'Bike ID'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9750ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_bikes = df[\"Bike ID\"].nunique()\n",
    "print(\"Total bikes used (unique): \", unique_bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c2360",
   "metadata": {},
   "source": [
    "### What are the proportions of user types (Subscriber vs Customer)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d341cf3",
   "metadata": {},
   "source": [
    "We need to tweak ```df.value_counts()``` to show our percentages.\n",
    "- *value.counts()* by itself only returns each each class member's row count\n",
    "- *value_counts(normalize=True)* divides said row count by total rows --> Decimal proportion\n",
    "- *.mul(100)* multiplies by 100 to get the percentage\n",
    "\n",
    "To list the user types and percentages we will generalise using the method ```.items()``` in an attempt to make the code more reusable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_types = df['User Type'].value_counts(normalize=True).mul(100).round(2)\n",
    "\n",
    "\n",
    "# There are only 2 user types in this case, so we could use\n",
    " # print(user_types.index[0], user_types.iloc[0])\n",
    " # print(user_types.index[1], user_types.iloc[1])\n",
    "\n",
    "# But let's try and generalise to cater for any number of class members. \n",
    "\n",
    "print(\"User Type\\tType percentage\\n================================\")\n",
    "\n",
    "for user_type_name, user_type_percentage in user_types.items():\n",
    "    print(f\"{user_type_name}\\t{user_type_percentage:.1f}%\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# print(user_types.items())\n",
    "\n",
    "\n",
    "# print(user_types.iloc[0])\n",
    "# print(user_types.iloc[1])\n",
    "\n",
    "\n",
    "#print(f'''User Type\\t\\Type percentage\n",
    "#      ================================\n",
    "#      {user_types.index[1]})\n",
    "#      '''\n",
    "\n",
    "\n",
    "# print(f\"Top start station:\\t{top_start_station.index[0]}. Trip count:\\t{top_start_station.iloc[0]}\")\n",
    "# print(f\"Top end station:\\t{top_end_station.index[0]}. Trip count:\\t{top_end_station.iloc[0]}\")\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca3798",
   "metadata": {},
   "source": [
    "Let's make a simple pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fa0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We'll use .index and .values as lists (\"Duck typing\")\n",
    "labels = user_types.index\n",
    "sizes = user_types.values\n",
    "\n",
    "# Plot the chart \n",
    "#   ( autopct='%1.1f%%' --> to show percentages inside each slice)\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "plt.title('Citi Bike user type by size (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd34a8f",
   "metadata": {},
   "source": [
    "### What is the age distribution of the users? <br>Which age group uses the service the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605633b6",
   "metadata": {},
   "source": [
    "As we can see below, the 35-44 age group is the most frequent service user group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec151017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User age distribution\n",
    "# Same as previous step, but we need to sort by user age as well\n",
    "\n",
    "user_ages = df['Age Groups'].value_counts(normalize=True).mul(100).round(2)\n",
    "\n",
    "# Sort by user age\n",
    "user_ages = user_ages.sort_index()\n",
    "\n",
    "print(\"User age bucket\\t\\tPercentage\\n===================================\")\n",
    "\n",
    "for user_age_bucket, user_age_percentage in user_ages.items():\n",
    "    print(f\"{user_age_bucket}\\t\\t\\t{user_age_percentage:.1f}%\")\n",
    "\n",
    "\n",
    "# labels = user_ages.index\n",
    "# sizes = user_ages.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a77ff",
   "metadata": {},
   "source": [
    "To highlight the age group uses the service the most, we can just pick out the highest-percentage bucket with a one-liner like so;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most frequent service user group:\", df['Age Groups'].value_counts().head(1).index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b9534",
   "metadata": {},
   "source": [
    "Let's make a pie chart and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d66a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use .index and .values as lists (\"Duck typing\")\n",
    "labels = user_ages.index\n",
    "sizes = user_ages.values\n",
    "\n",
    "# Plot the chart \n",
    "#   ( autopct='%1.1f%%' --> to show percentages inside each slice)\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "plt.title('Citi Bike service usage by Age Group (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec8005",
   "metadata": {},
   "source": [
    "Since we have a few groups with small percentage values, they clump together in the pie chart. To add insult to injury such groups aren't in a continuous age range, so grouping them together wouldn't be the cleanest option in our opinion.<br>Let's try a **Bar Chart** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff0c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ages.plot(kind='bar')\n",
    "plt.title('Citi Bike Usage by Age Group')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8c7cd",
   "metadata": {},
   "source": [
    "Now it's much easier to spot the age groups with smaller values.<br>Another benefit of the bar chart over the pie chart is a tidy layout of age groups in ascending order (cf. x-axis) for quick reference, while the highest and lowest values are still easily spotted as they stand out visually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abba0c",
   "metadata": {},
   "source": [
    "## 4. Temporal Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e7339",
   "metadata": {},
   "source": [
    "### How does the number of trips vary by weekday?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8ec67",
   "metadata": {},
   "source": [
    "First we make sure all timestamps are healthy -- they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c917304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check timestamp health\n",
    "print(\"Bad Start Time Timestamps: \",(pd.to_datetime(df['Start Time'], errors='coerce').isna().sum()))\n",
    "print(\"Bad Stop Time Timestamps: \",(pd.to_datetime(df['Stop Time'], errors='coerce').isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b9be7",
   "metadata": {},
   "source": [
    "Next, we organise all trips by weekday and reindex.\n",
    "<br>NB. Since the column 'Weekday' is a string, we need to manually provide the order of the days of the week.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "trips_by_weekday = df['Weekday'].value_counts()\n",
    "\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "trips_by_weekday = trips_by_weekday.reindex(weekday_order)\n",
    "\n",
    "print(trips_by_weekday)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec1128",
   "metadata": {},
   "source": [
    "Let's plot another bar chart to show these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0664f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Chart\n",
    "\n",
    "trips_by_weekday.plot(kind='bar')\n",
    "plt.title('Citi Bike Usage by Weekday (in # of trips)')\n",
    "plt.ylabel('# of trips')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a4e84",
   "metadata": {},
   "source": [
    "Now we can clearly see peak usage occurs on Wednesdays and Thursdays, and the trough on Saturdays and Sundays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba21fa0",
   "metadata": {},
   "source": [
    "### Which month or season has the most rides?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae573b35",
   "metadata": {},
   "source": [
    "We'll focus on months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc47f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_by_month = df['Month'].value_counts()\n",
    "top_rides_month = trips_by_month.idxmax()\n",
    "\n",
    "# Let's show the month name as well.\n",
    "Month_Names = {1:'January', 2:'February', 3: 'March'}\n",
    "\n",
    "print(f\"The month No. with most rides is: {top_rides_month} ({Month_Names[top_rides_month]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1eb5d",
   "metadata": {},
   "source": [
    "### What time of day do most trips start?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd93076",
   "metadata": {},
   "source": [
    "Before we apply ```value_counts()``` we must first split by hour.<br>\n",
    "Let's add a \"Start Hour\" column to the dataset for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f90592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"Start Hour\"\n",
    "df['Start Hour'] = df['Start Time'].dt.hour\n",
    "\n",
    "# Calculate top hour and trip count, show results\n",
    "top_start_hour = df['Start Hour'].value_counts().idxmax()\n",
    "top_start_hour_trips = df['Start Hour'].value_counts().max()\n",
    "print(f\"Most common hour (24 hr): {top_start_hour}.\\nTotal trips in that hour: {top_start_hour_trips}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4381737",
   "metadata": {},
   "source": [
    "## 5. Geographic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3154b24",
   "metadata": {},
   "source": [
    "### Which station pairs (start â†’ end) appear most often?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a03ee4",
   "metadata": {},
   "source": [
    "We can create a new column to gather trips and just apply ```value.counts()``` to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98904f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Trips'] = df['Start Station Name'] + ' > ' + df['End Station Name']\n",
    "print(\"Most common trip routes\\n=====================================\")\n",
    "df['Trips'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87130c04",
   "metadata": {},
   "source": [
    "\n",
    "### Are there any stations that appear only as start or only as end stations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c56a9",
   "metadata": {},
   "source": [
    "We can save the unique values for each station type, the subtract the sets both ways.\n",
    "Let's use a function to show the data.<br>\n",
    "As we can see in the results below, there are no unique start station names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b34cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_stations = set(df['Start Station Name'].unique())\n",
    "end_stations = set(df['End Station Name'].unique())\n",
    "\n",
    "start_only_stations = start_stations - end_stations\n",
    "end_only_stations = end_stations - start_stations\n",
    "\n",
    "\n",
    "\n",
    "def show_stations(station_set, station_set_name):\n",
    "    print(f\"Showing records for {station_set_name}\\n==============================================\")\n",
    "    if len(station_set) == 0:\n",
    "        print(\"There are no records of: \", station_set_name, \"\\n\")\n",
    "    else:\n",
    "        for station in station_set:\n",
    "            print(station)\n",
    "    \n",
    "\n",
    "\n",
    "show_stations(start_only_stations, \"start-only Stations\")\n",
    "show_stations(end_only_stations, \"end-only Stations\")\n",
    "\n",
    "# for station in start_only_stations:\n",
    "#    print(station)\n",
    "\n",
    "# print(len(start_only_stations))\n",
    "# print(len(end_only_stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062eea08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "283c72a3",
   "metadata": {},
   "source": [
    "## 6. Temperature and Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0fb0be",
   "metadata": {},
   "source": [
    "### Is there any visible relationship between temperature and trip duration?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93a329",
   "metadata": {},
   "source": [
    "This is called a *bivariate correlation analysis*, because it uses 2 variables -- in this case *temperature* and *trip duration*.\n",
    "We can use the method ```df.corr()``` which calculates Pearson's correlation coefficient. The scale of results are shown like this;\n",
    "- -1 or near: Strong negative correlation (ie. as one value increases the other decreases proportionally)\n",
    "-  0 or near: No correlation (ie. no linear relationship)\n",
    "- +1 or near: Strong positive correlation (ie. as one value increases the other increases proportionally)\n",
    "\n",
    "In this particular instance, as we can see below, there is no correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation coefficient\n",
    "\n",
    "correlation_r = df['Trip_Duration_in_min'].corr(df['Temperature'])\n",
    "print(\"The Pearson correlation coefficient is:\", correlation_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2be748",
   "metadata": {},
   "source": [
    "### How does average trip duration vary by season?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d69103",
   "metadata": {},
   "source": [
    "We can start by looking at average trip per season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f99bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart for trip duration average per Season\n",
    "\n",
    "avg_duration_by_season = df.groupby('Season')['Trip_Duration_in_min'].mean()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "avg_duration_by_season.plot(\n",
    "    kind='bar',\n",
    "    color=['#008000', '#0000FF']\n",
    ")\n",
    "\n",
    "plt.title('Average Trip Duration by Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Average Trip Duration (Minutes)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df222ab",
   "metadata": {},
   "source": [
    "There is hardly any difference to spot. Let's look at the mean and median values per season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ca995",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_stats = df.groupby('Season')['Trip_Duration_in_min'].agg(['mean', 'median'])\n",
    "print(seasonal_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc1a1d",
   "metadata": {},
   "source": [
    "Looking at the mean and median values makes us none the wiser. Let's make a box plot to visualise the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Generate the Box Plot\n",
    "df.boxplot(\n",
    "    column='Trip_Duration_in_min',\n",
    "    by='Season',\n",
    "    ax=plt.gca(),\n",
    "    grid=True,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "    medianprops=dict(color='red')\n",
    ")\n",
    "\n",
    "# Omit outliers --> not working!\n",
    "showfliers=False\n",
    "\n",
    "# Customizing the plot\n",
    "plt.title('Trip Duration Distribution by Season (Box Plot)', fontsize=14)\n",
    "plt.suptitle('') # Suppress pandas default title\n",
    "plt.xlabel('Season', fontsize=12)\n",
    "plt.ylabel('Trip Duration (Minutes)', fontsize=12)\n",
    "plt.ylim(0, 40)  # Focus on the main body of data (0-30 mins)\n",
    "\n",
    "# Tighten y-axis\n",
    "plt.ylim(0, 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3d083",
   "metadata": {},
   "source": [
    "So the variance is not in the absolute terms of mean and median but in the frequency distribution of the trips. L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7f30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the quantiles (percentiles) to calculate: Q1, Median (Q2), Q3\n",
    "quantiles = [0.25, 0.50, 0.75]\n",
    "\n",
    "# 1. Group by season and calculate the quartiles\n",
    "seasonal_quartiles = df.groupby('Season')['Trip_Duration_in_min'].quantile(quantiles).unstack()\n",
    "\n",
    "# 2. Rename columns for clarity\n",
    "seasonal_quartiles.columns = ['Q1 (25th)', 'Median (50th)', 'Q3 (75th)']\n",
    "\n",
    "# 3. Calculate the Interquartile Range (IQR)\n",
    "seasonal_quartiles['IQR'] = seasonal_quartiles['Q3 (75th)'] - seasonal_quartiles['Q1 (25th)']\n",
    "\n",
    "print(seasonal_quartiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe933e",
   "metadata": {},
   "source": [
    "So now we can establish;\n",
    "- The most frequent minimum trip duration is the same for both seasons: 4 minutes (Q1)\n",
    "- Typical trip duration is the same for both seasons: 5 minutes (median value)\n",
    "- The longest trips (Q3) are 1 minute longer in winter, which corresponds to a modest 12.5% increase relative to the 8-minute spring baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d77b8",
   "metadata": {},
   "source": [
    "## 7. Summary and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b4bcde",
   "metadata": {},
   "source": [
    "The Citi Bike service is generally used as a utility and short-trip commuter service. We base this opinion on trip duration and variance, and on identifying the most frequent end trip Stations.\n",
    "\n",
    "**Trip duration and variance**\n",
    "- Typical trip durations are between 5 and 8-9 minutes, despite the service limit of 45 minutes per trip for members ([Source: Citi Bikes HP - Pricing](https://citibikenyc.com/pricing))\n",
    "- Temperature has no bearing on trip duration\n",
    "- Trip duration variance by Season is low\n",
    "\n",
    "**End trip Stations**\n",
    "The top 5 destination stations (W 45 St & 8 Ave, E 15 St & 3 Ave, JCBS Depot, Broadway & W 36 St, Warren St & Church St) are transit hubs, commercial centers, or university adjacent areas. Last mile commuting, typically from home to a nearby subway station is likely the most frequent use case.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
